---
lightbox: true
---
# Fourier Transform {#sec-signal-fourier}

The fourier transform helps us convert a signal from the time domain to the frequency domain.
In this section our main concern is going to be one dimensional signals, but the concepts can be applied to multiple dimensions.

Before we can start defining the _Fourier Series_ we need to extend our notion of vector space to functions space.
This is done with _Hilbert_ spaces. 
The computational rules follow the same principal as in @def-vectorspace, what we want to investigate is the inner product.

::: {.callout appearance="simple"}
:::: {#def-hilbert-innerproduct} 
## Hilbert inner product
The _Hilbert inner product_ of two functions $f(x)$ and $g(x)$ is defined for $x \in [a, b]$ as:
$$
\langle f(x), g(x)\rangle = \int_a^b f(x) \overline{g}(x)\, \mathrm{d}x,
$$
where $\overline{g}(x)$ denotes the complex conjugate. 
::::
:::

At first this looks strange but it is closely related to our already known @def-dotproduct.

As a first step, if we move from real to complex vector spaces the transpose is replaced by the conjugate transposed or hermit transpose, in notation the $^\mathbf{T}$ becomes $^\mathbf{H}$.

Now consider a discrete version of $f$ and $g$ at regular intervals $\Delta x = \frac{b-a}{n-1}$ where 
$$
f_i = f(x_i) = f(a + (i - 1) \Delta x),\quad i = 1, \ldots n,
$$
same for $g_i$ and accordingly $x_1 = a + 0 \Delta x = a$ and $x_n = a + (n - 1)\Delta x = b$.

The inner product is than
$$
\langle f, g \rangle = \langle\left[\begin{array}{c}f_1 \\ f_2 \\ \vdots \\ f_n \end{array}\right], \left[\begin{array}{c}g_1 \\ g_2 \\ \vdots \\ g_n \end{array}\right] \rangle = \sum_{i=1}^n f_i \overline{g}_i = \sum_{i=1}^n f(x_i)\overline{g}(x_i).
$$

As this sum will increase by increasing $n$ we should normalize it by the factor $\Delta x$.

$$
\frac{b-a}{n-1} \langle g, f \rangle = \sum_{i=1}^n f(x_i)\overline{g}(x_i) \Delta x.
$$
If we now increase $n\to \infty$ we get $\Delta x \to 0$ and the sum transforms into the integral. 

::: {.callout appearance="simple"}
:::: {#def-hilbert-innerproduct} 
## Hilbert two norm
The _Hilbert two norm_ of the function $f(x)$ is defined for $x \in [a, b]$ as:
$$
\|f\|_2 = \sqrt{\langle f(x), g(x)\rangle} = \left(\int_a^b f(x) \overline{f}(x)\,\mathrm{d}x\right)^{\frac12},
$$
where $\overline{f}(x)$ denotes the complex conjugate. 

The set of all functions with bounded norm defines the Hilbert space $L^2(a, b)$, i.e. the set of all square integrable functions.
This space is also called the space of _Lebesgue_ integrable functions.
::::
:::

Similar as we saw projection in vector spaces related to the inner product this is true here as well. 

::: {.callout appearance="simple"}
:::: {#def-fourier-periodic} 
## Periodic function

We call a function $f\,:\, \mathbb{R} \to \mathbb{R}$ periodic with a period of $L>0$, $L$-periodic for short, if 
$$
f(x + L) = f(x),\quad\forall x \in \mathbb{R}.
$$

The following holds true for $L$-periodic functions:

1. If $L$ is a period than $nL$ for $n = 1, 2, 3, \ldots$ is a period as well.
1. If $f$ and $g$ are $L$-periodic, than $\alpha f + \beta g$ are $L$-periodic, for $\alpha, \beta \in \mathbb{C}$.
1. I $f$ is $L$-periodic it follows that $\forall a\in\mathbb{R}$
$$
\int_a^{a+T}f(x)\,\mathrm{d}x = \int_0^{T}f(x)\,\mathrm{d}x.
$$
1. If $f$ is $L$-periodic than $F(x)=f(\frac{x}{\omega})$ with $\omega = \frac{2\pi}{L}$ is $2\pi$-periodic.
::::
:::

The Fourier series is nothing else as the projection of a function with an integer period on the domain $[a, b]$ onto the orthogonal basis defined by the sine and cosine functions.

## Fourier Series

In Fourier analysis the first result is stated for a periodic and piecewise smooth function $f(x)$.

::: {.callout appearance="simple"}
:::: {#def-fourier-series} 
## Fourier Series
For a $L$-periodic function $f(x)$ we can write
$$
f(x) = \frac{a_0}{2} + \sum_{k=1}^\infty \left(a_k \cos\left(\omega kx\right)+ b_k \sin\left(\omega kx\right)\right),
$$ {#eq-fs}
for 
$$
\begin{align}
a_k = \frac{2}{L}\int_0^L f(x) \cos\left(\omega kx\right)\, \mathrm{d}x,\\
b_k = \frac{2}{L}\int_0^L f(x) \sin\left(\omega kx\right)\, \mathrm{d}x.
\end{align}
$$
where we can view the last two equations as the projection onto the orthogonal basis $\{\cos(kx), \sin(kx)\}_{k=0}^\infty$, i.e.
$$
\begin{align}
a_k = \frac{1}{\|\cos\left(\omega kx\right)\|_2^2} \langle f(x), \cos\left(\omega kx\right)\rangle, \\
b_k = \frac{1}{\|\sin\left(\omega kx\right)\|_2^2} \langle f(x), \sin\left(\omega kx\right)\rangle.
\end{align}
$$

If we perform a partial reconstruction by truncating the series at $M$ we get 
$$
\hat{f}_M(x) = \frac{a_0}{2} + \sum_{k=1}^M \left(a_k \cos\left(\omega kx\right)+ b_k \sin\left(\omega kx\right)\right).
$$
:::
::::

With the help of Euler's formula:
$$
\mathrm{e}^{\mathrm{i} kx} = \cos(kx) + \mathrm{i} \sin(kx)
$$ {#eq-euler}
we can rewrite @eq-fs as
$$
f(x) = \sum_{k=-\infty}^\infty c_k \mathrm{e}^{\omega\mathrm{i} kx}
$$
with 
$$
c_k = \frac{1}{L} \int_0^L f(x) \mathrm{e}^{-\omega\mathrm{i} kx}\, \mathrm{d}x.
$$
and for $n=1, 2, 3, \ldots$
$$
c_0 = \tfrac12 a_0, \quad c_n = \tfrac12 (a_n - \mathrm{i} b_n), \quad c_{-n} = \tfrac12 (a_n + \mathrm{i} b_n).
$$

::: {.callout-note}
If $f(x)$ is real valued than $c_k = \overline{c}_{-k}$.
:::

::: {.callout-tip appearance="simple" collapse="true" icon=false}
:::: {#exm-fourier-hat}

## Fourier Series of Hat functions

We test the Fourier Series with two different hat functions.
The first represents a triangle with constant slope up and down, the second a rectangle with infinite slope in the corners.

```{python}
#| label: fig-fourier_hat
#| fig-cap: "Fourier transform of a two hat functions."
#| fig-subcap:
#|   - "Sawtooth function and the reconstruction with 7 nodes"
#|   - "Nodes of the reconstruction"
#|   - "Step function and the reconstruction with various nodes"
#| layout-ncol: 1
#| code-fold: true
#| code-summary: "Show the code for the figure"
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.cm import get_cmap
%config InlineBackend.figure_formats = ["svg"]

# Parameters
L = 2 * np.pi
M = 7
M2 = 50
N = 101
# Hat functions
fun = lambda x, L: 0 if abs(x) > L / 4 else (1 - np.sign(x) * x * 4 / L)
fun2 = lambda x, L: 0 if abs(x) > L / 4 else 1

# x and y for the functions
x = np.linspace(-L/2, L/2, N)
dx = x[1] - x[0]
omega = np.pi * 2 / L

f = np.fromiter(map(lambda x: fun(x, L), x), x.dtype)
f2 = np.fromiter(map(lambda x: fun2(x, L), x), x.dtype)

# Necessary functions
scalarproduct = lambda f, g, dx: dx * np.vecdot(f, g)
a_coeff = lambda n, f: 2 / L * scalarproduct(f, np.cos(omega * n * x), dx)
b_coeff = lambda n, f: 2 / L * scalarproduct(f, np.sin(omega * n * x), dx)

# f_hat_0
f_hat = np.zeros((M+1, N))
f_hat[0, :] = 1/2 * a_coeff(0, f)
f2_hat = np.zeros((M2+1, N))
f2_hat[0, :] = 1/2 * a_coeff(0, f2)

# Computation of the approximation
a = np.zeros(M)
b = np.zeros(M)
for i in range(M):
    a[i] = a_coeff(i+1, f)
    b[i] = b_coeff(i+1, f)
    f_hat[i+1, :] = f_hat[i, :] + \
        a[i] * np.cos(omega * (i+1) * x) + \
        b[i] * np.sin(omega * (i+1) * x)

for i in range(M2):
    f2_hat[i+1, :] = f2_hat[i, :] + \
        a_coeff(i+1, f2) * np.cos(omega * (i+1) * x) + \
        b_coeff(i+1, f2) * np.sin(omega * (i+1) * x)

# Figures
plt.figure(0)
plt.plot(x, f, label=r"$f$")
plt.plot(x, f_hat[-1, :], label=r"$\hat{f_7}$")
plt.xticks([])
plt.legend()
plt.gca().set_aspect(1.5)

plt.figure(1)
plt.plot(x, f_hat[0, :], label=rf"$a_{0}$")
for i in range(M):
    plt.plot(x, a[i] * np.cos(omega * (i+1) * x), label=rf"$a_{i+1}\cos({i+1}\omega x$")
plt.legend(ncol=np.ceil((M+1)/2), bbox_to_anchor=(1, -0.1))
plt.xticks([])
plt.gca().set_aspect(1.5)

plt.figure(2)
plt.plot(x, f2, label=r"$f$")
plt.plot(x, f2_hat[7, :], label=r"$\hat{f}_7$")
plt.plot(x, f2_hat[20, :], label=r"$\hat{f}_{20}$")
plt.plot(x, f2_hat[50, :], label=r"$\hat{f}_{50}$")
plt.xlabel(r"$x$")
plt.legend()
plt.gca().set_aspect(1.5)

plt.show()
```
::::
:::

::: {.callout-tip appearance="simple" collapse="true" icon=false}
## {{< fa pen-to-square >}} Exercise - Self implementation @exm-fourier-hat

Implement the code yourself by filling out the missing sections:

```{python}
#| code-fold: false
#| eval: false
#| code-summary: "Code fragment for implementation."
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.cm import get_cmap

# Parameters
L = 2 * np.pi   # Interval
M = 7           # Nodes for the first function
M2 = 50         # Nodes for the second function
N = 101         # Interpolation points
# Hat functions
fun = lambda x, L: # tooth
fun2 = lambda x, L: # step

# x and y for the functions
x = # points for the evaluation ()
dx = x[1] - x[0]
omega = np.pi * 2 / L

f = # fun evaluated at x
f2 = # fun2 evaluated at x

# Necessary functions
scalarproduct = lambda f, g, dx: # see definition in the notes
a_coeff = lambda n, f: # see definition in the notes
b_coeff = lambda n, f: # see definition in the notes

# f_hat_0
f_hat = np.zeros((M+1, N))
f_hat[0, :] = # a_0 for f
f2_hat = np.zeros((M2+1, N))
f2_hat[0, :] = # a_0 for f2

# Computation of the approximation
a = np.zeros(M)
b = np.zeros(M)
for i in range(M):
    a[i] = a_coeff(i+1, f)
    b[i] = b_coeff(i+1, f)
    f_hat[i+1, :] = f_hat[i, :] + \
        a[i] * np.cos(omega * (i+1) * x) + \
        b[i] * np.sin(omega * (i+1) * x)

for i in range(M2):
    f2_hat[i+1, :] = f2_hat[i, :] + \
        a_coeff(i+1, f2) * np.cos(omega * (i+1) * x) + \
        b_coeff(i+1, f2) * np.sin(omega * (i+1) * x)

# Figures
plt.figure(0)
plt.plot(x, f, label=r"$f$")
plt.plot(x, f_hat[-1, :], label=r"$\hat{f_7}$")
plt.xticks([])
plt.legend()
plt.gca().set_aspect(1.5)

plt.figure(1)
plt.plot(x, f_hat[0, :], label=rf"$a_{0}$")
for i in range(M):
    plt.plot(x, a[i] * np.cos(omega * (i+1) * x), label=rf"$a_{i+1}\cos({i+1}\omega x$")
plt.legend(ncol=np.ceil((M+1)/2), bbox_to_anchor=(1, -0.1))
plt.xticks([])
plt.gca().set_aspect(1.5)

plt.figure(2)
plt.plot(x, f2, label=r"$f$")
plt.plot(x, f2_hat[7, :], label=r"$\hat{f}_7$")
plt.plot(x, f2_hat[20, :], label=r"$\hat{f}_{20}$")
plt.plot(x, f2_hat[50, :], label=r"$\hat{f}_{50}$")
plt.xlabel(r"$x$")
plt.legend()
plt.gca().set_aspect(1.5)

plt.show()
```
:::

::: {.callout-note}
The phenomenon that the truncated Fourier series oscillates in @fig-fourier_hat-3 due to the discontinuity of the function is called the Gibbs phenomenon.
:::

## Fourier Transform

The Fourier Series is defined for $L$-periodic functions.
The Fourier transform extends this to functions with the domain extended to $\pm\infty$.

Let us start of with the series representation we already know:
$$
f(x) = \sum_{k=-\infty}^\infty c_k \mathrm{e}^{\mathrm{i} \omega k x}
$$
with the coefficients
$$
c_k = \frac{1}{2L} \int_{-L}^{L} f(x) \mathrm{e}^{-\mathrm{i} \omega_k x}\, \mathrm{d}x,
$$
with $\omega_k=\frac{k\pi}{L} = k\Delta \omega$.

If we now perform the transition for $L \to \infty$ resulting in $\Delta\omega \to 0$ and basically moving from discrete frequencies to a continuous set of frequencies.
This results in
$$
f(x) = \lim_{\Delta \omega \to 0} \sum_{k=-\infty}^\infty \frac{\Delta \omega}{2\pi}
\int_{-\tfrac{\pi}{\Delta \omega}}^{\tfrac{\pi}{\Delta \omega}} f(\xi) \mathrm{e}^{-\mathrm{i} k \Delta \omega \xi}\, \mathrm{d}\xi\,\, \mathrm{e}^{\Delta\omega\mathrm{i} kx}
$$
which is a Riemann integral and the kernel becomes the Fourier Transform of our function. 

::: {.callout appearance="simple"}
:::: {#def-fourier-transform} 
## Fourier Transform
A function $f\,:\, \mathbb{R} \to \mathbb{R}$ is called fourier transposable if
$$
\hat{f}(\omega) = \mathcal{F}\{f(x)\} = \int_{-\infty}^{\infty} f(x)\mathrm{e}^{-\mathrm{i} \omega x}\, \mathrm{d}x
$$
exists for all $\omega\in\mathbb{R}$.
In this case we call $\hat{f}(\omega) \equiv \mathcal{F}\{f(x)\}$ the **Fourier transform** of $f(x)$.

The **inverse Fourier transform** is defined as
$$
\mathcal{F}^{-1}\{\hat{f}(\omega)\} = \frac{1}{2 \pi}\int_{-\infty}^{\infty} \hat{f}(\omega)\mathrm{e}^{\mathrm{i} \omega x}\, \mathrm{d}\omega
$$
::::
:::

::: {.callout-note}

The pair $(f, \hat{f})$ is often called the _Fourier transform pair_. 

The two integrals converge, as long as both functions are Lebesgue integrable, i.e. 
$$\int_{-\infty}^\infty|f(x)|\, \mathrm{d}x \le \infty,$$
or $f, \hat{f} \in L^1[(-\infty, \infty)]$.
:::

As could be expected, the Fourier transform has properties that lead to computational advantages.

For tow functions $f, g \in L^1[(-\infty, \infty)]$ and $\alpha, \beta\in\mathbb{C}$ the following properties hold:

(@) **Linearity**
$$
\mathcal{F}\{\alpha f(x) + \beta g(x)\} = 
\alpha \mathcal{F}\{f(x)\} + \beta \mathcal{F}\{g(x)\} = 
\alpha \hat{f}(\omega)+ \beta \hat{g}(\omega),
$$
and 
$$
\mathcal{F}^{-1}\{\alpha \hat{f}(\omega) + \beta \hat{g}(\omega)\} = 
\alpha \mathcal{F}^{-1}\{\hat{f}(\omega)\} + \beta \mathcal{F}^{-1}\{\hat{g}(\omega)\} = 
\alpha f(x) + \beta g(x).
$$

(@) **Conjugation** 
$$
\mathcal{F}\{\overline{f(x)}\} = \overline{\hat{f}(-\omega)}.
$$

(@) **Scaling**, for $\alpha \neq 0$
$$
\mathcal{F}\{f(\alpha x)\} = \frac{1}{|\alpha|}\hat{f}\left(\frac{\omega}{\alpha}\right).
$$

(@) **Drift in time**, for $a\in\mathbb{R}$
$$
\mathcal{F}\{f(x - a)\} = \mathrm{e}^{-\mathrm{i}\omega a}\hat{f}(\omega).
$$

(@) **Drift in frequency**, for $a\in\mathbb{R}$

$$
\mathrm{e}^{\mathrm{i} a x} \mathcal{F}\{f(x - a)\} = \hat{f}(\omega - a).
$$

(@) If $f$ is **even** or **odd**, than $\hat{f}$ is even or odd, respectively.

(@) **Derivative in time**
$$
\mathcal{F}\{\partial_x f(x)\} = \mathrm{i} \omega \hat{f}(\omega)
$$
We are going to prove this by going through the lines
$$
\begin{align}
\mathcal{F}\left\{\frac{d}{d\,x}f(x)\right\} &= \int_{-\infty}^\infty f'(x)\mathrm{e}^{-\mathrm{i}\omega a}\, \mathrm{d}x \\
&= \left[f(x)\mathrm{e}^{-\mathrm{i}\omega a}\right]_{-\infty}^\infty - \int_{-\infty}^\infty -\mathrm{i} \omega f(x)\mathrm{e}^{-\mathrm{i}\omega a}\, \mathrm{d}x \\
&= \mathrm{i} \omega \int_{-\infty}^\infty f(x)\mathrm{e}^{-\mathrm{i}\omega a}\, \mathrm{d}x \\
&= \mathrm{i} \omega \mathcal{F}\{f(x)\}
\end{align}
$$
For higher derivatives we get
$$
\mathcal{F}\{\partial_x^n f(x)\} = \mathrm{i}^n \omega^n \hat{f}(\omega)
$$

(@) **Derivative in frequency**
$$
\mathcal{F}\{x^n f(x)\} = \mathrm{i}^n \partial_\omega^n\hat{f}(\omega)
$$

(@) The **convolution** of two functions is defined as 
$$
(f \ast g)(x) = \int_{-\infty}^{\infty}f(x - \xi) g(\xi)\, \mathrm{d}\xi,
$$
and for the Fourier transform
$$
\mathcal{F}\{(f \ast g)(x)\} = \hat{f} \cdot \hat{g}.
$$

(@) **Parseval's Theorem**
$$
\|f\|_2^2 = \int_{-\infty}^{\infty}|f(x)|^2\, \mathrm{d}x = \frac{1}{2 \pi}\int_{-\infty}^{\infty}|\hat{f}(\omega)|^2\, \mathrm{d}\omega
$$
stating that the Fourier Transform preserves the 2-norm up to a scaling factor.

## Discrete Fourier Transform (DFT)

The Discrete Fourier Transform (DFT) is a way of approximating the Fourier transform on discrete vectors of data and it essentially a discretized version of the Fourier transform by sampling the function and numerical integration. 


::: {.callout appearance="simple"}
:::: {#def-fourier-dft} 

## Discrete-Fourier Transform
For equally spaced values $x_k = k\Delta x$, for $k\in\mathbb{Z}$ and $\Delta x>0$ and the discrete values of the function evaluations $f_k=f(x_k)$.
If the function is periodic with $L=N\Delta x$ than the discrete Fourier transform is given as
$$
\hat{f}_k = \sum_{j=1}^{N-1}f_j\, \mathrm{e}^{-\mathrm{i} j k\tfrac{2 \pi}{N}},
$$
and its inverse (iDFT) as
$$
f_k = \frac{1}{N}\sum_{j=1}^{N-1}\hat{f}_j\, \mathrm{e}^{\mathrm{i} j k\tfrac{2 \pi}{N}}.
$$
::::
:::

As we can see, the DFT is a linear operator and therefore it can be written as a matrix vector product
$$
\left[
    \begin{array}{c} \hat{f}_1 \\ \hat{f}_2 \\ \hat{f}_3 \\ \vdots \\ \hat{f}_N \end{array}
\right]
=
\left[
    \begin{array}{ccccc} 1 & 1 & 1 & \dots & 1 \\
                         1 & \omega_N & \omega_N^2 & \dots & \omega_N^{N-1} \\  
                         1 & \omega_N^2 & \omega_N^4 & \dots & \omega_N^{2(N-1)} \\
                         \vdots & \vdots & \ddots & \vdots\\
                         1 & \omega_N^{N-1} & \omega_N^{2(N-1)} & \dots & \omega_N^{(N-1)^2 } \\
    \end{array}
\right] 
\left[
    \begin{array}{c} f_1 \\ f_2 \\ f_3 \\ \vdots \\ f_N \end{array}
\right]
$$
with $\omega_N = \exp({-\mathrm{i} \tfrac{2 \pi}{N}})$. 

::: {.callout-note}
The matrix of the DFT is a unitary Vandermonte matrix.
:::

As we can transfer the properties of the Fourier transform to the DFT we get the nice properties for sampled signals.

The downside of the DFT is that it does not scale well for large $N$ as the matrix-vector multiplication is $\mathcal{O}(N^2)$ and becomes slow. 

